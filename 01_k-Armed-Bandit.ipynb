{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Armed Bandit\n",
    "\n",
    "- The *value* is the *expected reward*\n",
    "  $$\n",
    "  \\begin{align*}\n",
    "  q_\\star(a) \\doteq& \\mathbb{E}[R_t|A_t=a]\\quad\\forall a\\in\\{1,\\cdots,k\\} \\\\\n",
    "                  =& \\sum_r{p(r|a)r}\n",
    "  \\end{align*}\n",
    "  $$\n",
    "- The goal is to *maximize* the *expected reward*\n",
    "  $$\n",
    "  \\underset{a}{\\mathrm{argmax}}\\ q_\\star(a)\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value of an Action\n",
    "\n",
    "- $q_\\star(a)$ is not known, so we *estimate* it\n",
    "\n",
    "### Sample-Average Method\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Q_t(a) \\doteq& \\frac{\\text{sum of rewards when $a$ taken prior to $t$}}{\\text{# of times $a$ taken prior to $t$}} \\\\\n",
    "            =& \\frac{\\sum^{t-1}_{i=1}{R_i}}{t-1}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental update\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Q_{n_1} =& \\frac{1}{n}\\sum^{n}_{i=1}{R_i} \\\\\n",
    "        =& \\frac{1}{n}(R_n + \\sum^{n-1}_{i=1}{R_i}) \\\\\n",
    "        =& \\frac{1}{n}(R_n + (n - 1)\\frac{1}{n-1}\\sum^{n-1}_{i=1}{R_i}) \\\\\n",
    "        =& \\frac{1}{n}(R_n + nQ_n - Q_n) \\\\\n",
    "        =& Q_n + \\frac{1}{n}(R_n - Q_n)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Incremental update rule\n",
    "\n",
    "- This is an example of *Non-stationary bandit problem*\n",
    "\n",
    "$$\n",
    "\\mathit{NewEstimate} \\leftarrow \\mathit{OldEstimate} + \\mathit{StepSize}(\\mathit{Target} - \\mathit{OldEstimate})\n",
    "$$\n",
    "$$\n",
    "Q_{n+1} = Q_n + \\alpha_n(R_n - Q_n) \\\\\n",
    "\\alpha_n \\rightarrow [0,1]\n",
    "$$\n",
    "\n",
    "### Decaying past rewards\n",
    "\n",
    "- Inital action-value decreases exponentially with time\n",
    "- The rewards further back in contribute exponentially less to the sum\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Q_{n+1} =& Q_n + \\alpha_n(R_n - Q_n) \\\\\n",
    "        =& \\alpha R_n + (1-\\alpha)\\alpha R_{n-1} + (1-\\alpha)^2 R_{n-2} + \\cdots + (1-\\alpha)^{n-1}\\alpha R_1 + (1-\\alpha)^nQ_1 \\\\\n",
    "        =& (1-\\alpha)^n\\underbrace{Q_1}_{\\text{initial action-value}} + \\sum^{n}_{i=1}{\\alpha(1-\\alpha)^{n-i}R_i}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}